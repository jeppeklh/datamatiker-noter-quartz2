## A) Beskriv hvilke test I har udført i jeres projekt. Hvad testede I? Hvad blev ikke testet. Forklar hvorfor og reflekter over konsekvenserne.
I vores projekt har vi primært arbejdet med white‑box tests i form af unit‑tests. 

Vi har været opmærksomme på, at tests normalt udføres på flere niveauer – herunder integration, brugeroplevelse og sikkerhed – men på grund af begrænset tid og manglende erfaring, har vi ikke haft mulighed for at implementere disse testtyper systematisk. 

Vi har dog tænkt i forhold til sikkerhed og robusthed undervejs i udviklingen, og vi er bevidste om, at vi i fremtidige projekter bør udvide testdækningen til også at inkludere disse niveauer for at opnå en mere helhedsorienteret **kvalitetssikring**.

Vi har prioriteret test i de dele af systemet, hvor vi vurderede, at der var høj **kompleksitet** og hvor en fejl ville have stor betydning for korrekthed og brugerens oplevelse.

---

### Overblik over udførte tests
#### White-box (programmeringsniveau) – unit-tests
Til whitebox-tests

**Vores tilgang** 
Vi prioriterede at skrive tests for kernefunktionalitet, som vi vurderede havde størst betydning for korrekthed og stabilitet i applikationen. 
Fokus har især været på forretningslogik og inoputvalidering, hvor fejl kunne få direkte konsekvenser for slutbrugerens oplevelse eller dataintegriteten. 
Vi valgte primært at teste de komponenter, hvor vi havde en klar forståelse af kravene, og hvor vi kunne isolere afhængigheder.

**Hvad testede vi?**

- `RejsepakkeService`: beregning af samlede priser og validering af inputparametre.
- `UserValidator`: e-mail-format, obligatoriske felter osv.
- `ExtendedUserService` og `VacationRequestTreeService` blev testet isoleret med Moq-mocking af alle afhængigheder.


**Hvordan?**

- MSTest i .NET.
- TestDrivenDevelopment-principper brugt i et par kernescenarier, men størstedelen af tests er skrevet _efter_ implementering, fordi vi mødte nye frameworks og ikke kendte metode-signaturer på forhånd. (**Usikkerhed**)
- **Navngivningskonvention**: `MethodName_WhenCondition_ExpectResult`, så det er tydeligt, hvilken forretningsregel der valideres.


**Fordele**

- Hurtig, automatiske regressionstests - frem for manuel testing (ting kan gå uopdagede).
- Giver sikkerhed for, at services fungerer korrekt, før de indgår i UI eller integration.

**Eksempel** 
`VacationRequestTreeService` blev skrevet til at samle og erstatte spredt logik – unit-tests sikrede, at ny kode matchede alle gamle anvendelser, inden vi slettede det gamle.


##### Validering & Verificering

**Validering** 
Vi **validerede** ved at sikre, at tests kunne spores direkte til funktionelle krav og designbeskrivelser fra vores Low Level Design.

**Verificering** 
Vi **verificerede**  i form af at testresultater blev automatisk logget, og vi gennemgik dem løbende i forbindelse med at kildekoden blev opdateret. 
Desuden har vi gennemgået dem i fællesskab til code-reviews.

---

#### Gray-box (designniveau) – enkelte integrationsscenarier
**Vores tilgang** 
Her testede vi primært overgangene mellem lag og enkelte kritiske interaktioner mellem komponenter, hvor vi vurderede risikoen for fejl som værende størst.

**Hvad testede vi?**
- Simple database-integration med in-memory DB for at sikre, at repository-metoder returnerer forventede objekter.

- Navigation og adgangskontrol i Customer- og Employee-pages: f.eks. forsøg på at indlæse en kundeside, hvor kunden ikke eksisterer.


**Hvordan?**
- Manuelle tests og enkelte automatiserede tests mod in-memory-databasen.

- Ingen fuld end-to-end-integration mod den rigtige database.

---

#### Black-box (brugerniveau) – manuelle UI-tests
**Vores tilgang** 
På grund af manglende tid og erfaring med automatiserede UI-tests valgte vi at fokusere på manuelle gennemgange af brugerflows for at opdage åbenlyse fejl og uhensigtsmæssigheder.

**Hvad testede vi?**
- Grundlæggende brugerflows: login, søgning, booking, betaling og visning af rejsepakker.

- Manuelle tjek i Chrome for at sikre, at UI-komponenter renderes og valideringsbeskeder vises korrekt.

**Begrænsning**
- Ingen systematisk testrapport; testene var afhængige af, hvem der udførte dem, og hvilke scenarier de huskede.
        
---

### Hvad blev ikke testet – og hvorfor
Vi har ikke udført følgende testtyper, primært pga. begrænset tid, erfaring og teknisk opsætning:

#### End-to-end-automatisering  
Vi har ikke skrevet automatiserede tests, der kører hele bruger­flowet fra UI til database. 
Det kræver et setup og en læringskurve, som vi ikke nåede.  

**Konsekvens** 
Mulige sammenbrud i brugerflows opdages først manuelt – sent i processen.

#### Performance- og stresstest  
Ikke prioriteret, da vi forventede lav belastning.

**Konsekvens**
Risiko for langsom opførsel i drift.

#### Sikkerhedstest  
Ingen penetrationstest eller scanning. 
Kun grundlæggende sikkerhedsprincipper anvendt (f.eks. login-lås ved brute-force, parameterisede queries) (login og rollebaseret adgang var security by design)

**Konsekvens** 
Potentielle sårbarheder (SQL-injektion, XSS m.v.) kan være uopdagede.

#### Database- og API-integration i rigtigt miljø  
Vores tests kørte kun mod en lokal database. 
Vi har ikke prøvet i et miljø, der ligner produktion med netværks­latency og rigtige data.  

**Konsekvens**: 
Fejl i repository eller transaktioner kan opstå, når systemet deployeres i et rigtigt miljø.

#### UX- og tilgængelighedstest med slutbrugere
Ingen brugere uden for teamet har testet systemet.

**Konsekvens** 
Risiko for oversete problemer i brugerrejse og barrierer for forskellige brugergrupper.

---

### Refleksion over konsekvenser
**Fragmenteret integration** 
Lokal DB-tests giver ikke et retvisende billede af driftsscenarier.

**Manglende automatisering** 
Regression kan ske ubemærket.

**Usikker performance og sikkerhed** 
Uforudsigelige problemer kan opstå ved drift.

**Begrænset brugerindsigt** 
Ingen brugerfeedback fra rigtige brugere kan betyde, at flows, UI og valideringer virker åbenlyse for os – men ikke for dem.

---

### Konklusion
Vi har fokuseret på solide unit-tests (white-box), suppleret med light integration (gray-box) og manuelle black-box-checks, men mangler automatiserede end-to-end-, performance-, sikkerheds-, og UX-tests.

Konsekvensen er øget risiko for regressionsfejl, ydeevne- og sikkerhedsproblemer og utilgængelighed og ukendt brugeroplevelse. 

Til fremtidige projekter bør vi afsætte tid til mindst et basis-niveau af automatiseret end to end-test, performance-scan og en simpel penetrationstest, samt involvere rigtige slutbrugere i løbende UX-tests.

[[13. Spørgsmål#B) Beskriv forskellige typer af test og test niveauer samt hvornår, hvordan og hvorfor disse anvendes. Derudover skal du redegøre for væsentlige forskelle i test ved agile og vandfaldsmodeller|Test B spørgsmål]]

---

## b) Beskriv én ny systemudviklingsmetoder (en anden end RUP, som du arbejdede med på 1. semester). Hvilke værktøjer benyttes og hvordan dækkes de forskellige fokusområder?
### Rapid Application Development (RAD)
Jeg har valgt at beskrive **Rapid Application Development (RAD)** – en agil systemudviklingsmetode, som fokuserer på hurtig levering af software gennem hyppig prototyping og tæt brugerinddragelse. 
I modsætning til fx vandfaldsmodellen prioriterer RAD iterativ udvikling og hurtig feedback fremfor detaljeret forhåndsspecifikation.

[[Rod Stephens - Beginning Software Engineering (2022, Wiley) - libgen.li.pdf#page=503&selection=43,0,75,70|Principper her]]

---

### Faser i RAD
RAD er inddelt i fire hovedfaser:

**Requirements Planning (kravplanlægning)**  
Brugere, ledelse og udviklere afklarer forretningsbehov og scope i workshops (fx JAD). 
Det giver er en overordnet kravdefinition og projektgodkendelse.

**User Design (brugerdesign)**  
Brugerne deltager aktivt i udvikling af modeller og prototyper. 
Der anvendes modeller som UML og simple GUI-prototyper (Hi-fi wireframes). 
Design og krav justeres iterativt i workshops.

**Construction (konstruktion/programmering)**  
Systemet bygges iterativt. 
Udviklere programmerer og tester komponenter med løbende brugerfeedback. 
Ofte bruges modulær udvikling, frameworks og CASE-værktøjer. 
og laver intgrerede Tests (unit- og integrationstest).

**Cutover (udrulning)**  
Systemet gøres klar til drift: dataoverførsel, test, oplæring og pilotdrift. 
Der kan anvendes forskellige cutover-strategier som _pilot_, _modulær_ eller _parallel_.

Før disse faser starter, bruges ofte en kort _Iteration 0_ til at opsætte værktøjer, testmiljø og få overblik over krav og aktører.

---

### Fokusområder i RAD
**Projektstyring** 
RAD anvender timeboxing og iterationer til at styre scope og fremdrift. 
Kommunikation og planlægning sker i korte feedback-loop med brugerne.

**Kravindsamling** 
Workshops og prototyping sikrer løbende kravafklaring. 
Krav dokumenteres typisk via user stories, use cases og modeller.

**High level design** 
Arkitektur og processer modelleres tidligt i processen. 
UML-diagrammer og mock-ups (wireframes) visualiserer struktur og funktionalitet.

**Low level design** 
Detaljerede specifikationer og datamodeller udvikles undervejs. 
Dokumenteres ofte via sekvensdiagrammer, databasemodeller eller DCD.

**Programmering** 
Koden bygges i iterationer. 
RAD understøtter genbrug, kodegenerering og hurtige builds. 
Versionsstyring anvendes.

**Test** 
Test er integreret i udviklingen og foregår både undervejs (unit/integration) og ved afslutning (bruger accept test).

**Udrulning** 
RAD understøtter forskellige udrulningsstrategier. 
Fokus er på hurtig idriftsættelse og feedback fra brugerne. 
fx pilotdrift.

**Vedligehold** 
Fejlrettelser og forbedringer sker som nye iterationer. 
RAD egner sig godt til _perfective_, _adaptive_, _corrective_ og _preventive_ vedligehold pga. den løbende feedback og iteration.

---

### Hvornår passer RAD?
RAD egner sig godt til projekter med **høj usikkerhed** og **lav kompleksitet**:

**Høj usikkerhed** 
Kravene er uklare eller ændrer sig ofte. 
Her fungerer RAD godt, fordi feedback fra prototyper og brugertests hurtigt kan omsættes til ændringer i systemet. 
Det reducerer risikoen for at bygge et system, der ikke matcher reelle behov.

**Lav kompleksitet** 
Der er få integrationer, simple datamodeller og få aktører. 
Det betyder, at udviklingen ikke bremses af teknisk **kompleksitet** eller afhængighed til mange eksterne systemer og aktører.
RAD kræver korte beslutningsveje og tættest muligt samarbejde mellem udviklere og brugere.


RAD passer derfor bedst i mindre teams med direkte adgang til brugerne, hvor man prioriterer fleksibilitet, hurtig værdi og kontinuerlig forbedring over detaljeret langsigtet planlægning.



SPRING OVER (til evt. spørgsmål)

|   |   |   |
|---|---|---|
|Metode|Anvendelse i RAD|Fordel i RAD-sammenhæng|
|**Pilot**|Rulle ny prototypeløsning ud til en mindre brugergruppe først|Tæt feedback med minimal risiko før bred udrulning|
|**Parallel**|Køre gammel og ny løsning sideløbende indtil stabilitet opnået|Sikker fallback, understøtter kontinuerlig iteration|
|**Modulær**|Gradvis udrulning af enkelte komponenter eller services|Passer til RADs genbrug af prototyper og komponentbiblioteker|
|Strangler Fig|Skifte gamle funktioner ud med nye moduler én ad gangen|Tilpasser sig RADs iterative udviklingsmodel|

|   |   |   |
|---|---|---|
|Vedligeholdelsestype|Beskrivelse|Hvordan det passer til RAD|
|**Perfectiv (forbedrende)**|Tilføje nye eller forbedre eksisterende funktioner|Nye user stories prioriteres i baglog og itereres hurtigt|
|**Adaptive (tilpassende)**|Justeringer ved miljøændringer (OS, hardware, API)|Hurtige prototyper sikrer nem validering af ændringer|
|**Corrective (rettende)**|Fejlrettelser og bugfixes|Kontinuerlig integration og test i RAD fanger fejl tidligt|
|**Preventive (forbyggende)**|Refaktorering og strukturforbedringer|Timeboxing af refaktorering sikrer kodekvalitet uden forsinkelser|

### Værktøjer/metoder i RAD-faser
---

|Fokusområde|Eksempler på teknikker/værktøjer|
|---|---|
|Projektstyring|Iteration planning, timeboxing, burn-down charts|
|Kravindsamling|JAD, user stories, use cases, prototyper|
|High level design|UML, wireframes, domænemodeller|
|Low level design|Sekvensdiagrammer, datamodeller|
|Programmering|Modulær kode, frameworks, versionsstyring|
|Test|Testplaner, enhedstest, accepttest|
|Udrulning|Pilot/parallel cutover, brugerdokumentation|
|Vedligehold|Fejllogging, CI/CD, versionsstyring|

---

### Konklusion
RAD er en metode, der dækker alle fokusområder gennem **iterativ** udvikling, tæt brugerinddragelse og tidlig **validering**. 

Den kræver dog, at projektet passer til metoden: 
der skal være fleksibilitet, tætte brugerkontakter og mulighed for hurtige iterationer.